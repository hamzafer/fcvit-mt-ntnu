# FCViT
* 비전 트랜스포머 기반 좌표 예측을 통한 직소 퍼즐 풀이
* ![fcvit 아키텍처](https://github.com/user-attachments/assets/87ac17a0-2590-4bdc-bb03-a8f1937add0c)
* ImageNet 3x3 퍼즐 시각화
* ![퍼즐 시각화](https://github.com/user-attachments/assets/8239f58b-772f-4676-8e77-c9fd514a82d9)
<br>

## 목차
### 👨‍🏫 개요
### ✅ 문제 정의
### 💡 가설 설정
### 🔬 실험 및 검증
### 📊 결론
<br>



## 👨‍🏫 개요
* __개요__: 
  * 직소퍼즐은 작은 조각을 재조립하여 완전한 이미지를 만드는 작업으로, 패턴 인식과 공간 추론과 같은 인지 능력이 필요합니다. 직소퍼즐을 직소퍼즐을 푸는 것은 인간에게는 간단해 보일 수 있지만, 컴퓨터 비전 모델에게는 복잡한 도전과제 입니다. 놀랍게도, 조각의 수가 9개로 구성된 쉬운 퍼즐 조차 제대로 풀지 못하는 것이 컴퓨터 비전 모델의 현재 수준 입니다. 
  * 우리는 이러한 문제를 2가지 아이디어를 적용하여 해결하고자 합니다. 첫번째로 대부분의 기존 모델이 분류 알고리즘을 사용하는데, 이를 회귀 알고리즘으로 변경하고자 합니다. 두번째로 CNN 대신에 ViT (Vision Transformer)를 인코더로 활용하여 문제를 해결하고자 합니다.
* __기간/인원__: 2023.02.01 ~ 2024.12.31 (2년) / 3명
* __주요 역할__: 
  * 분류 알고리즘에서 발생하는 문제점을 회귀 알고리즘으로 해결
  * 딥러닝 모델 ViT (Vision Transformer) 아키텍처 수정
  * 자기지도학습을 위한 데이터 처리 및 학습 전략 설계
  * 관련 논문의 모델들을 PyTorch로 다시 구현
  * 학습 내용과 학습 과정 시각화
* __배운 점__: 
  * 딥러닝 모델의 속도와 성능 문제를 창의적 사고로 해결
  * 논문을 읽고 이해하는 능력과 코드로 구현하는 능력 향상
  * 대용량 데이터셋 (ImageNet) 사용 방법 숙지
  * 리눅스 서버 GPU 환경 모델 학습 방법 숙지
  * Python 프로그래밍 숙련도 향상
<br>



## ✅ 문제 정의
![직소퍼즐 학습](https://github.com/user-attachments/assets/302663fc-07b0-438e-acb8-8791b5e00455)
* __직소퍼즐 학습이란?__
  * 직소퍼즐 학습은 무작위로 섞인 퍼즐 조각들을 재조립하는 것입니다.
  * 컴퓨터 비전 분야에서 까다로운 과제이며, 패턴 인식과 공간 추론이 필요합니다.
* __왜 직소퍼즐 학습의 문제를 해결해야 하는가?__
  * 직소퍼즐을 학습한 딥러닝 모델은 `패턴 인식과 공간 추론 능력` 이 뛰어납니다.
  * 직소퍼즐을 학습하여 다양한 분야에서 활용하는 대표적인 예시로 `객체 인식`이 있습니다.
  * 객체 인식은 대표적으로 `자율 주행`과 같은 기술에서 활용합니다.
  * 직소퍼즐은 `자기지도학습` 입니다.
  * 사람의 라벨링 없이 오직 이미지만 있어도 학습이 가능합니다.
  * Vision 분야의 오랜 숙제인 `대용량 사전학습`의 방법 중에 하나로 사용할 수 있습니다.
* __어떻게 해결할 것인가?__
  * 방법: JigsawCFN 모델의 아키텍처를 수정합니다.
  * JigsawCFN은 전이학습을 염두한 end-to-end 모델이기 때문에 선정했습니다.
<br>



## 💡 가설 설정
* __개선 포인트 1: 분류 알고리즘__
  * ![분류 회귀](https://github.com/user-attachments/assets/5aa8f5bf-67ae-4c64-86a0-53fbff89cc5a)
  * 기존 학습전략은 `분류 알고리즘`을 사용하여 가능한 모든 순열들의 확률을 예측합니다.
  * 퍼즐조각의 개수와 순열은 비례 관계이며, `순열은 기하급수적으로 증가`한다.
  * (ex. 4개 퍼즐조각은 4! (24개), 9개 퍼즐 조각은 9! (362,880개)의 가능한 순열)
  * 따라서, 모델 사이즈(=모델이 계산해야할 확률)도 기하급수적으로 증가합니다.
  * `분류 알고리즘`은 직소퍼즐 학습의 효율성과 확장성에 문제를 야기하고 있습니다.
* __가설 설정 1: 회귀 알고리즘으로 변경하면 효율성과 확장성 문제를 해결할 수 있다.__
  * 제안하는 학습전략은 `회귀 알고리즘`을 사용하여 퍼즐조각의 수평, 수직 좌표 값 (h, v)을 예측합니다.
  * 퍼즐조각의 개수와 좌표는 비례 관계이며, `좌표의 개수는 선형적으로 증가`한다.
  * (ex. 4개의 퍼즐 조각은 4x2 (=8개), 9개 퍼즐 조각은 9x2 (=18개)의 좌표만 예측)
  * 따라서, 모델 사이즈(=모델이 계산해야할 좌표)는 선형적으로 증가합니다.
  * `회귀 알고리즘` 모델은 상대적으로 크기가 작고 `효율적`이며, 퍼즐 조각의 수가 늘어나더라도 커버할 수 있는 `확장성`이 있습니다. 추가적으로 이 방법은 `사람의 행동패턴과 유사`한 특징이 있습니다.
* __개선 포인트 2: CNN 인코더__
  * ![CNN 인코더](https://github.com/user-attachments/assets/abcc7319-ff45-4d2f-82eb-9f6483bc4417)
  * 대부분의 기존 모델들은 `CNN 인코더`를 사용합니다.
  * CNN은 `지역적 특징 추출 한계`가 있습니다.
  * 지역적 특징으로는 전체 이미지를 보고 퍼즐을 조립하는 것에 한계가 있습니다.
  * CNN을 최신 아키텍처로 변경해 성능을 개선할 필요가 있습니다.
* __가설 설정 2: ViT 인코더로 대체하면 더 좋은 성능을 얻을 수 있다.__
  * `ViT 인코더`를 사용하면 더 높은 성능을 기대할 수 있습니다.
  * ViT는 `전역적 특징 추출 능력`이 뛰어나기 때문에 퍼즐 문제에 적합합니다.
  * backbone을 쉽게 교체할 수 있도록 설계하여 개발 용이성을 확보 합니다.
<br>



## 🔬 실험 및 검증
* __FCViT 아키텍처__
  * ![fcvit 아키텍처](https://github.com/user-attachments/assets/87ac17a0-2590-4bdc-bb03-a8f1937add0c)
  * 자기지도학습을 위한 데이터 처리 및 학습 전략 설계
    * 인풋 이미지를 9개의 퍼즐 조각으로 자릅니다.
    * 각 퍼즐 조각에 고유 수평 수직 좌표 (h, v)를 부여합니다.
    * 고유 좌표 9개를 무작위로 섞습니다.
    * (이때 섞은 좌표가 학습의 정답인 label이 됩니다.)
    * 섞인 좌표를 기준으로 퍼즐 조각을 섞습니다.
    * (이 섞인 이미지가 모델에 입력 됩니다.)
  * 회귀 알고리즘과 ViT 인코더를 적용한 직소 퍼즐 모델 아키텍처 설계
    * 입력: 224x224 사이즈의 퍼즐 문제 (=섞인 이미지)
    * 인코더: 섞인 이미지에서 특징을 추출, ViT-16/B
    * 예측기: 특징을 활용해 고유 좌표 예측, 3개의 MLP, dim=1000, ReLU 사용
    * 출력: 9개의 예측된 수평 수직 좌표 (h, v)
    * 손실함수: 정답과 예측 사이의 차이 계산, SmoothL1 Loss
* __데이터셋__
  * 학습 및 평가: ImageNet, JPwLEG
  * 평가: CIFAR10, iNaturalists19, MET
* __실험1: ImageNet 데이터셋 학습 및 평가__
  * ![table 1](https://github.com/user-attachments/assets/66ab979a-f70b-49d2-9737-1b25c7d5819c)
  * ImageNet 3×3 퍼즐을 학습 및 평가합니다.
  * 기존의 SOTA 모델과 비교 시 83.3%에서 90.6%으로 개선했습니다.
  * 결론적으로 FCViT가 SOTA를 달성했습니다. 
* __실험2: 인코더 교체 평가__
  * ![table 5](https://github.com/user-attachments/assets/1053cd56-45dc-4694-931e-ac48ea1c9969)
  * 회귀 알고리즘 학습 전략만 사용한 FCCNN은 기존 모델보다 성능이 좋습니다.
  * 이 부분은 `가설 설정 1`이 참임을 뒷받침하는 근거가 됩니다.
  * ViT 인코더를 추가로 사용한 FCViT는 FCCNN에 비해 성능이 더 좋습니다.
  * 이 부분은 `가설 설정 2`가 참임을 뒷받침하는 근거가 됩니다.
* __실험3: 일반화 성능 평가__
  * ![table 3](https://github.com/user-attachments/assets/83b24f71-4afd-458e-b91b-551aa35bc6e3)
  * 오직 ImageNet 데이터셋만 학습하고 다른 데이터셋에 대하여 평가 합니다.
  * 이 평가는 모델이 robustness한 특징을 추출할 수 있는지 평가 합니다.
  * robustness란 학습한 데이터셋에 국한되지 않은 일반화된 성능을 의미 입니다.
  * 기존 모델은 10% ~ 38% 감소 하지만, 제안 모델: 1% ~ 21% 감소 합니다.
  * 따라서 기존 모델에 비해 FCViT가 더 robustness한 특징을 추출할 수 있습니다.
* __실험4: 계산효율성 평가__
  * ![table 4](https://github.com/user-attachments/assets/c62c7b1e-239e-4350-860d-628eb3c6878a)
  * FCViT를 기존 SOTA 모델인 JPDVT와 비교합니다.
  * 모델 크기 (131M -> 87M)과 추론시간 (3.4 s -> 0.016 s)을 개선했습니다.
  * FCViT는 더 효율적인 모델이면서 동시에 더 효과적인 모델 입니다.
  * JigsawCFN은 1K의 순열만 커버할 수 있는 모델입니다.
  * 이 모델이 9!의 순열을 커버한다면 크기가 약 360배 커집니다.
  * 반면 FCViT는 1K의 순열, 9!의 순열 모두에서 동일한 크기를 가집니다.
<br>



## 📊 결론
* __결론1: 좌표 예측과 ViT를 통한 직소 퍼즐 문제 접근__
  * 기존 모델들은 분류 알고리즘으로 문제를 접근 했습니다.
  * FCViT는 기존 모델과 다르게 회귀 알고리즘으로 문제를 접근했습니다.
  * 모델 사이즈를 34% 개선했고, 추론 시간을 1/200 수준으로 줄였습니다.
  * 기대효과: FCViT로 기존에 불가능했던 4x4, 5x5 퍼즐 문제에 도전할 수 있습니다.
* __결론2: 직소 퍼즐 문제 SOTA 달성__
  * ImageNet 데이터셋에서 정확도를 7.3%를 개선해 90.6%로 SOTA를 달성했습니다.
  * 일반화 성능에서 1% ~ 20% 감소로 기존 모델보다 더 robustness한 표현을 학습했습니다.
  * 기대효과: 직소 퍼즐 문제를 사전학습으로 사용하여 다양한 분야에서 활용할 수 있습니다.
<br>
